# å¿«é€Ÿå¼€å§‹æŒ‡å—

## 1. ç¯å¢ƒå‡†å¤‡

### å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### ç³»ç»Ÿè¦æ±‚
- Python 3.7+
- PyTorch 1.9+
- CUDA 10.2+ (æ¨èGPUè®­ç»ƒ)
- å†…å­˜ 16GB+ (å»ºè®®)

## 2. æ•°æ®å‡†å¤‡

### æ•°æ®é›†æ ¼å¼
```
dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/          # è®­ç»ƒå›¾åƒ
â”‚   â””â”€â”€ masks/           # è®­ç»ƒæ©ç 
â””â”€â”€ val/
    â”œâ”€â”€ images/          # éªŒè¯å›¾åƒ  
    â””â”€â”€ masks/           # éªŒè¯æ©ç 
```

### æ”¯æŒçš„æ ¼å¼
- å›¾åƒ: JPG, PNG, TIFF
- æ©ç : PNG (äºŒå€¼å›¾åƒ, 0-èƒŒæ™¯, 255-å‰æ™¯)

## 3. é…ç½®è°ƒæ•´

ç¼–è¾‘ `configs/config.yaml`:

```yaml
# åŸºæœ¬é…ç½®
model:
  in_channels: 3        # RGB=3, ç°åº¦=1
  base_channels: 64     # åŸºç¡€é€šé“æ•°
  prototype_dim: 256    # åŸå‹ç»´åº¦

# è®­ç»ƒé…ç½®  
training:
  batch_size: 8         # æ ¹æ®GPUå†…å­˜è°ƒæ•´
  learning_rate: 0.001
  epochs: 200

# æ•°æ®é…ç½®
data:
  image_size: [512, 512]  # ç›®æ ‡å›¾åƒå°ºå¯¸
```

## 4. æ¨¡å‹æµ‹è¯•

```bash
# æµ‹è¯•æ¨¡å‹ç»“æ„
python test_model.py

# æŸ¥çœ‹ä½¿ç”¨ç¤ºä¾‹
python examples.py
```

## 5. å¼€å§‹è®­ç»ƒ

```bash
# ä¿®æ”¹train.pyä¸­çš„æ•°æ®è·¯å¾„
# ç„¶åè¿è¡Œè®­ç»ƒ
python train.py
```

## 6. æ¨¡å‹æ¨ç†

```bash
# ä¿®æ”¹inference.pyä¸­çš„æ¨¡å‹å’Œå›¾åƒè·¯å¾„
python inference.py
```

## 7. è‡ªå®šä¹‰ä½¿ç”¨

### åˆ›å»ºæ¨¡å‹
```python
from models.enhanced_medical_seg import create_enhanced_medical_seg_net

# é»˜è®¤é…ç½®
model = create_enhanced_medical_seg_net()

# è‡ªå®šä¹‰é…ç½®
config = {
    'in_channels': 1,
    'base_channels': 32,
    'prototype_dim': 128
}
model = create_enhanced_medical_seg_net(config)
```

### è®­ç»ƒ
```python
# è®­ç»ƒæ¨¡å¼
loss_dict = model(images, masks, training=True)
total_loss = loss_dict['total_loss']
total_loss.backward()
```

### æ¨ç†
```python
# æ¨ç†æ¨¡å¼
model.eval()
with torch.no_grad():
    outputs = model(images, training=False)
    predicted_mask = outputs['mask']
```

## 8. æ¨¡å‹ç‰¹ç‚¹

- âœ… å¤šå°ºåº¦ç‰¹å¾æå–ä¸èåˆ
- âœ… å¯¹æ¯”å­¦ä¹ å¢å¼ºç‰¹å¾è¡¨ç¤º  
- âœ… ä¸ç¡®å®šæ€§å»ºæ¨¡ä¸çŸ«æ­£
- âœ… å¤šä»»åŠ¡å­¦ä¹ (åˆ†å‰²+åˆ†ç±»)
- âœ… åŸå‹ä¸æŸå¤±åé¦ˆæœºåˆ¶
- âœ… é”™è¯¯èšç„¦çš„è‡ªé€‚åº”ä¼˜åŒ–

## 9. æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**å†…å­˜ä¸è¶³**
- å‡å°batch_size
- é™ä½image_size  
- å‡å°‘base_channels

**è®­ç»ƒä¸æ”¶æ•›**
- æ£€æŸ¥æ•°æ®æ ‡æ³¨è´¨é‡
- è°ƒæ•´å­¦ä¹ ç‡
- è°ƒæ•´æŸå¤±æƒé‡

**æ¨ç†é€Ÿåº¦æ…¢**
- ä½¿ç”¨GPU
- å‡å°æ¨¡å‹å°ºå¯¸
- ä½¿ç”¨æ¨¡å‹é‡åŒ–

### æ€§èƒ½ä¼˜åŒ–

**GPUè®­ç»ƒ**
```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)
```

**æ··åˆç²¾åº¦è®­ç»ƒ**
```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
with autocast():
    loss = model(images, masks, training=True)['total_loss']
```

**æ•°æ®å¹¶è¡Œ**
```python
if torch.cuda.device_count() > 1:
    model = nn.DataParallel(model)
```

## 10. è¿›é˜¶ä½¿ç”¨

### æŸå¤±æƒé‡è°ƒæ•´
```python
loss_weights = {
    'mask_loss': 1.0,      # ä¸»åˆ†å‰²æŸå¤±
    'fg_loss': 0.5,        # å‰æ™¯æŸå¤±
    'bg_loss': 0.5,        # èƒŒæ™¯æŸå¤±  
    'uncertainty_loss': 0.3 # ä¸ç¡®å®šæ€§æŸå¤±
}
```

### æ¨¡å‹åˆ†æ
```python
summary = model.get_model_summary()
print(f"å‚æ•°é‡: {summary['total_parameters']:,}")
```

### ç‰¹å¾å¯è§†åŒ–
```python
# è·å–ä¸­é—´ç‰¹å¾è¿›è¡Œåˆ†æ
outputs = model(images, training=False)
entropy_map = outputs['entropy']
attention_map = outputs['attention_map']
```

---

ğŸ‰ **æ­å–œï¼æ‚¨å·²æˆåŠŸè®¾ç½®å¢å¼ºåŒ»å­¦å›¾åƒåˆ†å‰²ç½‘ç»œï¼**

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ç¤ºä¾‹ä»£ç æˆ–æ£€æŸ¥é…ç½®æ–‡ä»¶ã€‚
